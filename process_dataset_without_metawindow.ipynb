{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "258c639d",
   "metadata": {},
   "source": [
    "# Process Dataset without meta_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c7c6372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import dlib\n",
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e033566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular EAR\n",
    "def calculate_ear(eye_points):\n",
    "    A = distance.euclidean(eye_points[1], eye_points[5])\n",
    "    B = distance.euclidean(eye_points[2], eye_points[4])\n",
    "    C = distance.euclidean(eye_points[0], eye_points[3])\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9057416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular MAR\n",
    "def calculate_mar(mouth_points):\n",
    "    A = distance.euclidean(mouth_points[2], mouth_points[8])\n",
    "    B = distance.euclidean(mouth_points[3], mouth_points[7])\n",
    "    C = distance.euclidean(mouth_points[4], mouth_points[6])\n",
    "    D = distance.euclidean(mouth_points[0], mouth_points[5])\n",
    "    mar = (A + B + C) / (2.0 * D)\n",
    "    return mar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce1f712a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para estimar ángulo de cabeza\n",
    "def calculate_head_angle(landmarks):\n",
    "    model_points = np.array([\n",
    "        (0.0, 0.0, 0.0),  # Nariz\n",
    "        (0.0, -330.0, -65.0),  # Barbilla\n",
    "        (-225.0, 170.0, -135.0),  # Ojo izquierdo\n",
    "        (225.0, 170.0, -135.0),  # Ojo derecho\n",
    "        (-150.0, -150.0, -125.0),  # Boca izquierda\n",
    "        (150.0, -150.0, -125.0)  # Boca derecha\n",
    "    ])\n",
    "    image_points = np.array([\n",
    "        (landmarks.part(30).x, landmarks.part(30).y),  # Nariz\n",
    "        (landmarks.part(8).x, landmarks.part(8).y),  # Barbilla\n",
    "        (landmarks.part(36).x, landmarks.part(36).y),  # Ojo izquierdo\n",
    "        (landmarks.part(45).x, landmarks.part(45).y),  # Ojo derecho\n",
    "        (landmarks.part(48).x, landmarks.part(48).y),  # Boca izquierda\n",
    "        (landmarks.part(54).x, landmarks.part(54).y)  # Boca derecha\n",
    "    ], dtype=\"double\")\n",
    "    \n",
    "    focal_length = 640  # Aproximado para webcam\n",
    "    center = (640 / 2, 480 / 2)\n",
    "    camera_matrix = np.array([[focal_length, 0, center[0]],\n",
    "                             [0, focal_length, center[1]],\n",
    "                             [0, 0, 1]], dtype=\"double\")\n",
    "    dist_coeffs = np.zeros((4, 1))\n",
    "    _, rotation_vector, _ = cv2.solvePnP(model_points, image_points, camera_matrix, dist_coeffs)\n",
    "    angle = np.linalg.norm(rotation_vector) * 180 / np.pi\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e2eac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para contar parpadeos\n",
    "def count_blinks(ears, ear_threshold=0.2):\n",
    "    blinks = 0\n",
    "    prev_ear = ears[0]\n",
    "    for ear in ears[1:]:\n",
    "        if prev_ear > ear_threshold and ear <= ear_threshold:\n",
    "            blinks += 1\n",
    "        prev_ear = ear\n",
    "    return blinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50b9903d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para extraer características de una imagen\n",
    "def extract_features_from_image(image_path, detector, predictor):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        return None\n",
    "    faces = detector(img)\n",
    "    for face in faces:\n",
    "        landmarks = predictor(img, face)\n",
    "        left_eye = [(landmarks.part(i).x, landmarks.part(i).y) for i in range(36, 42)]\n",
    "        right_eye = [(landmarks.part(i).x, landmarks.part(i).y) for i in range(42, 48)]\n",
    "        mouth = [(landmarks.part(i).x, landmarks.part(i).y) for i in range(48, 68)]\n",
    "        ear = (calculate_ear(left_eye) + calculate_ear(right_eye)) / 2.0\n",
    "        mar = calculate_mar(mouth)\n",
    "        head_angle = calculate_head_angle(landmarks)\n",
    "        return {'ear': ear, 'mar': mar, 'head_angle': head_angle}\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3c672f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para procesar el dataset\n",
    "def process_dataset(drowsy_dir, notdrowsy_dir, detector, predictor, window_size=20):\n",
    "    videos = {}\n",
    "    # Procesar carpeta drowsy\n",
    "    for img_name in os.listdir(drowsy_dir):\n",
    "        match = re.match(r\"(\\d+_\\w+_\\w+)_(\\d+)_drowsy\\.jpg\", img_name)\n",
    "        if match:\n",
    "            video_id_base, frame_num = match.groups()\n",
    "            video_id = f\"{video_id_base}_drowsy\"\n",
    "            if video_id not in videos:\n",
    "                videos[video_id] = {'frames': [], 'label': 1}\n",
    "            videos[video_id]['frames'].append((int(frame_num), os.path.join(drowsy_dir, img_name)))\n",
    "    \n",
    "    # Procesar carpeta notdrowsy\n",
    "    for img_name in os.listdir(notdrowsy_dir):\n",
    "        match = re.match(r\"(\\d+_\\w+_\\w+)_(\\d+)_notdrowsy\\.jpg\", img_name)\n",
    "        if match:\n",
    "            video_id_base, frame_num = match.groups()\n",
    "            video_id = f\"{video_id_base}_notdrowsy\"\n",
    "            if video_id not in videos:\n",
    "                videos[video_id] = {'frames': [], 'label': 0}\n",
    "            videos[video_id]['frames'].append((int(frame_num), os.path.join(notdrowsy_dir, img_name)))\n",
    "    \n",
    "    # Ordenar frames y extraer características\n",
    "    data = []\n",
    "    for video_id, info in videos.items():\n",
    "        info['frames'].sort()  # Ordenar por número de fotograma\n",
    "        print(f\"Video {video_id}: Inicio={info['frames'][0][0]}, Fin={info['frames'][-1][0]}, Etiqueta={info['label']}, Imágenes={len(info['frames'])}\")\n",
    "        \n",
    "        ears, mars, head_angles = [], [], []\n",
    "        for _, frame_path in info['frames']:\n",
    "            features = extract_features_from_image(frame_path, detector, predictor)\n",
    "            if features:\n",
    "                ears.append(features['ear'])\n",
    "                mars.append(features['mar'])\n",
    "                head_angles.append(features['head_angle'])\n",
    "        \n",
    "        if len(ears) >= window_size:\n",
    "            for i in range(0, len(ears) - window_size + 1):\n",
    "                window_ears = ears[i:i + window_size]\n",
    "                window_mars = mars[i:i + window_size]\n",
    "                window_angles = head_angles[i:i + window_size]\n",
    "                blink_freq = count_blinks(window_ears)\n",
    "                data.append({\n",
    "                    'video_id': video_id,\n",
    "                    'ear_mean': np.mean(window_ears),\n",
    "                    'ear_std': np.std(window_ears),\n",
    "                    'ear_min': np.min(window_ears),\n",
    "                    'mar_mean': np.mean(window_mars),\n",
    "                    'mar_std': np.std(window_mars),\n",
    "                    'mar_max': np.max(window_mars),\n",
    "                    'head_angle_mean': np.mean(window_angles),\n",
    "                    'blink_freq': blink_freq,\n",
    "                    'label': info['label']\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bada25b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video 001_glasses_sleepyCombination_drowsy: Inicio=599, Fin=2747, Etiqueta=1, Imágenes=2149\n",
      "Video 001_glasses_slowBlinkWithNodding_drowsy: Inicio=464, Fin=1920, Etiqueta=1, Imágenes=1217\n",
      "Video 001_glasses_yawning_drowsy: Inicio=339, Fin=1849, Etiqueta=1, Imágenes=1007\n",
      "Video 001_noglasses_sleepyCombination_drowsy: Inicio=330, Fin=2710, Etiqueta=1, Imágenes=2381\n",
      "Video 001_noglasses_slowBlinkWithNodding_drowsy: Inicio=398, Fin=1851, Etiqueta=1, Imágenes=1154\n",
      "Video 001_noglasses_yawning_drowsy: Inicio=196, Fin=1871, Etiqueta=1, Imágenes=1676\n",
      "Video 002_glasses_sleepyCombination_drowsy: Inicio=314, Fin=2878, Etiqueta=1, Imágenes=2565\n",
      "Video 002_glasses_slowBlinkWithNodding_drowsy: Inicio=395, Fin=2035, Etiqueta=1, Imágenes=1544\n",
      "Video 002_glasses_yawning_drowsy: Inicio=432, Fin=2066, Etiqueta=1, Imágenes=1635\n",
      "Video 002_noglasses_sleepyCombination_drowsy: Inicio=239, Fin=2656, Etiqueta=1, Imágenes=2418\n",
      "Video 002_noglasses_slowBlinkWithNodding_drowsy: Inicio=209, Fin=1809, Etiqueta=1, Imágenes=1365\n",
      "Video 002_noglasses_yawning_drowsy: Inicio=268, Fin=1770, Etiqueta=1, Imágenes=1069\n",
      "Video 005_glasses_sleepyCombination_drowsy: Inicio=287, Fin=2921, Etiqueta=1, Imágenes=2635\n",
      "Video 005_glasses_slowBlinkWithNodding_drowsy: Inicio=344, Fin=2252, Etiqueta=1, Imágenes=1909\n",
      "Video 005_glasses_yawning_drowsy: Inicio=298, Fin=2297, Etiqueta=1, Imágenes=1835\n",
      "Video 005_noglasses_sleepyCombination_drowsy: Inicio=249, Fin=3191, Etiqueta=1, Imágenes=2943\n",
      "Video 005_noglasses_slowBlinkWithNodding_drowsy: Inicio=223, Fin=2252, Etiqueta=1, Imágenes=2030\n",
      "Video 005_noglasses_yawning_drowsy: Inicio=407, Fin=2639, Etiqueta=1, Imágenes=1640\n",
      "Video 006_glasses_sleepyCombination_drowsy: Inicio=128, Fin=2848, Etiqueta=1, Imágenes=2570\n",
      "Video 006_glasses_slowBlinkWithNodding_drowsy: Inicio=316, Fin=508, Etiqueta=1, Imágenes=193\n",
      "Video 001_glasses_nonsleepyCombination_notdrowsy: Inicio=0, Fin=3329, Etiqueta=0, Imágenes=3330\n",
      "Video 001_glasses_sleepyCombination_notdrowsy: Inicio=0, Fin=598, Etiqueta=0, Imágenes=599\n",
      "Video 001_glasses_slowBlinkWithNodding_notdrowsy: Inicio=0, Fin=1516, Etiqueta=0, Imágenes=704\n",
      "Video 001_glasses_yawning_notdrowsy: Inicio=0, Fin=1558, Etiqueta=0, Imágenes=843\n",
      "Video 001_noglasses_nonsleepyCombination_notdrowsy: Inicio=0, Fin=2731, Etiqueta=0, Imágenes=2732\n",
      "Video 001_noglasses_sleepyCombination_notdrowsy: Inicio=0, Fin=329, Etiqueta=0, Imágenes=330\n",
      "Video 001_noglasses_slowBlinkWithNodding_notdrowsy: Inicio=0, Fin=1719, Etiqueta=0, Imágenes=698\n",
      "Video 001_noglasses_yawning_notdrowsy: Inicio=0, Fin=195, Etiqueta=0, Imágenes=196\n",
      "Video 002_glasses_nonsleepyCombination_notdrowsy: Inicio=0, Fin=2933, Etiqueta=0, Imágenes=2934\n",
      "Video 002_glasses_sleepyCombination_notdrowsy: Inicio=0, Fin=313, Etiqueta=0, Imágenes=314\n",
      "Video 002_glasses_slowBlinkWithNodding_notdrowsy: Inicio=0, Fin=501, Etiqueta=0, Imágenes=492\n",
      "Video 002_glasses_yawning_notdrowsy: Inicio=0, Fin=431, Etiqueta=0, Imágenes=432\n",
      "Video 002_noglasses_nonsleepyCombination_notdrowsy: Inicio=0, Fin=2678, Etiqueta=0, Imágenes=2679\n",
      "Video 002_noglasses_sleepyCombination_notdrowsy: Inicio=0, Fin=238, Etiqueta=0, Imágenes=239\n",
      "Video 002_noglasses_slowBlinkWithNodding_notdrowsy: Inicio=0, Fin=669, Etiqueta=0, Imágenes=445\n",
      "Video 002_noglasses_yawning_notdrowsy: Inicio=0, Fin=1487, Etiqueta=0, Imágenes=702\n",
      "Video 005_glasses_nonsleepyCombination_notdrowsy: Inicio=0, Fin=3072, Etiqueta=0, Imágenes=2978\n",
      "Video 005_glasses_sleepyCombination_notdrowsy: Inicio=0, Fin=286, Etiqueta=0, Imágenes=287\n",
      "Video 005_glasses_slowBlinkWithNodding_notdrowsy: Inicio=0, Fin=343, Etiqueta=0, Imágenes=344\n",
      "Video 005_glasses_yawning_notdrowsy: Inicio=0, Fin=2089, Etiqueta=0, Imágenes=463\n",
      "Video 005_noglasses_nonsleepyCombination_notdrowsy: Inicio=0, Fin=3301, Etiqueta=0, Imágenes=3302\n",
      "Video 005_noglasses_sleepyCombination_notdrowsy: Inicio=0, Fin=248, Etiqueta=0, Imágenes=249\n",
      "Video 005_noglasses_slowBlinkWithNodding_notdrowsy: Inicio=0, Fin=222, Etiqueta=0, Imágenes=223\n",
      "Video 005_noglasses_yawning_notdrowsy: Inicio=0, Fin=1748, Etiqueta=0, Imágenes=1000\n",
      "Video 006_glasses_nonsleepyCombination_notdrowsy: Inicio=0, Fin=2867, Etiqueta=0, Imágenes=2868\n",
      "Video 006_glasses_sleepyCombination_notdrowsy: Inicio=0, Fin=2759, Etiqueta=0, Imágenes=279\n",
      "Video 006_glasses_slowBlinkWithNodding_notdrowsy: Inicio=0, Fin=1021, Etiqueta=0, Imágenes=829\n",
      "Características guardadas en features_without_metawindow.csv\n"
     ]
    }
   ],
   "source": [
    "# Directorios del dataset\n",
    "drowsy_dir = \"dataset/drowsy\"\n",
    "notdrowsy_dir = \"dataset/notdrowsy\"\n",
    "\n",
    "# Cargar detector y predictor\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"face_landmarks/shape_predictor_68_face_landmarks.dat\")  # Descarga este archivo\n",
    "\n",
    "# Procesar dataset\n",
    "df = process_dataset(drowsy_dir, notdrowsy_dir, detector, predictor)\n",
    "df.to_csv(\"features_without_metawindow.csv\", index=False)\n",
    "print(\"Características guardadas en features_without_metawindow.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
